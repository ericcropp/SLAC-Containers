{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f79f63b1-f554-4489-a552-104b6617fc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from UTILITY_quickstart import *\n",
    "import yaml\n",
    "\n",
    "with open('setLattice_defaults.yml', 'r') as file:\n",
    "    importedDefaultSettings = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45a9d06a-d692-444b-8e0b-9931f1aa3934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment set to:  /Users/nmajik/Documents/SLAC/FACET2-Bmad-PyTao\n",
      "Tracking to L0BFEND\n",
      "CSR on\n",
      "Overwriting lattice with setLattice() defaults\n",
      "No defaults file provided to setLattice(). Using setLattice_defaults.yml\n",
      "Number of macro particles = 10000.0\n"
     ]
    }
   ],
   "source": [
    "tao = initializeTao(\n",
    "    inputBeamFilePathSuffix = '/beams/nmmToL0AFEND_2bunch_2024-02-16Clean/2024-02-16_2bunch_1e5Downsample_nudgeWeights.h5',\n",
    "    #inputBeamFilePathSuffix = '/beams/L0AFEND_facet2-lattice.h5',\n",
    "\n",
    "    csrTF = True,\n",
    "    numMacroParticles=1e4,\n",
    "    #loadDefaultLatticeTF=False,\n",
    "    lastTrackedElement=\"L0BFEND\" #Initially, only want to load PInit. This is overriden in propagateToBEGBC20()\n",
    "\n",
    ")\n",
    "\n",
    "trackBeam(tao)\n",
    "PInit = ParticleGroup(data=tao.bunch_data(\"L0AFEND\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81e60ee4-cc1c-471f-8450-3ed53e56e0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'L1PhaseSet': (-30, -10), 'L2PhaseSet': (-50, -30), 'Q1EkG': (0, 388), 'Q2EkG': (-364, 0), 'Q3EkG': (0, 299), 'Q4EkG': (0, 304), 'Q5EkG': (-117, 0), 'Q6EkG': (-301, 0), 'S1ELkG': (0, 2590), 'S2ELkG': (-21706, 0), 'S3ELkG': (-2625, 0), 'S3ERkG': (-2603, 0), 'S2ERkG': (-21638, 0), 'S1ERkG': (0, 2601)}\n",
      "\n",
      "makingChangesUpstreamOfBEGBC20 = True\n"
     ]
    }
   ],
   "source": [
    "targetBunchSpacing = 200e-6\n",
    "#makingChangesUpstreamOfBEGBC20 = True #Set automatically based on pbounds\n",
    "optimizerCaresAboutTransverse = 1 #1 or 0\n",
    "\n",
    "\n",
    "pbounds = {\n",
    "    'L1PhaseSet': (-30, -10),\n",
    "    'L2PhaseSet': (-50, -30),\n",
    "    \n",
    "    \"Q1EkG\":  eval(importedDefaultSettings[\"Q1EkGBounds\"]),\n",
    "    \"Q2EkG\":  eval(importedDefaultSettings[\"Q2EkGBounds\"]),\n",
    "    \"Q3EkG\":  eval(importedDefaultSettings[\"Q3EkGBounds\"]),\n",
    "    \"Q4EkG\":  eval(importedDefaultSettings[\"Q4EkGBounds\"]),\n",
    "    \"Q5EkG\":  eval(importedDefaultSettings[\"Q5EkGBounds\"]),\n",
    "    \"Q6EkG\":  eval(importedDefaultSettings[\"Q6EkGBounds\"]),\n",
    "    \n",
    "    \"S1ELkG\": eval(importedDefaultSettings[\"S1ELkGBounds\"]),\n",
    "    \"S2ELkG\": eval(importedDefaultSettings[\"S2ELkGBounds\"]),\n",
    "    \"S3ELkG\": eval(importedDefaultSettings[\"S3ELkGBounds\"]),\n",
    "    \"S3ERkG\": eval(importedDefaultSettings[\"S3ERkGBounds\"]),\n",
    "    \"S2ERkG\": eval(importedDefaultSettings[\"S2ERkGBounds\"]),\n",
    "    \"S1ERkG\": eval(importedDefaultSettings[\"S1ERkGBounds\"]),\n",
    "}\n",
    "\n",
    "print(pbounds)\n",
    "\n",
    "makingChangesUpstreamOfBEGBC20 = 'L1PhaseSet' in pbounds\n",
    "print(f\"\\nmakingChangesUpstreamOfBEGBC20 = {makingChangesUpstreamOfBEGBC20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c8c357-a2a7-4e99-bdb1-4e53ed6e5393",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704ad00f-d1d2-42f6-a734-50be8ad97a45",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63ed0772-8ef8-4cdb-a890-83a3d7c5fd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagateToBEGBC20(\n",
    "    centerXYatBEGBC20 = False    \n",
    "): \n",
    "\n",
    "    ##################################\n",
    "    #Propagate to BEGBC20 and save result\n",
    "    ##################################\n",
    "    makeBeamActiveBeamFile(PInit)\n",
    "    \n",
    "    tao.cmd(f'set beam_init track_start = L0AFEND')\n",
    "    lastTrackedElement = \"BEGBC20\"\n",
    "    tao.cmd(f'set beam_init track_end = {lastTrackedElement}')\n",
    "\n",
    "    trackBeam(tao)\n",
    "\n",
    "    P = ParticleGroup(data=tao.bunch_data(lastTrackedElement))\n",
    "\n",
    "    ##################################\n",
    "    #Optional!! Center in x and y\n",
    "    ##################################\n",
    "    if centerXYatBEGBC20:\n",
    "        print(f\"\"\"Centering beam at BEGBC20, old values (x, xp, y, yp): {P[\"mean_x\"]} ,{P[\"mean_xp\"]}, {P[\"mean_y\"]} ,{P[\"mean_yp\"]} \"\"\")\n",
    "        P.x = P.x - np.mean(P.x)\n",
    "        P.y = P.y - np.mean(P.y)\n",
    "        P.px = P.px - np.mean(P.px)\n",
    "        P.py = P.py - np.mean(P.py)\n",
    "    \n",
    "    makeBeamActiveBeamFile(P)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8673098-2194-4553-be9e-34a017119a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareToSimulateFromBEGBC20toEnd():\n",
    "    #####################################################\n",
    "    #Import the BEGBC20 beam and prepare to simulate to end\n",
    "    #####################################################\n",
    "\n",
    "    tao.cmd(f'set beam_init track_start = BEGBC20')\n",
    "    tao.cmd(f'set beam_init track_end = end')\n",
    "    tao.cmd('reinit beam')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1e0d14-7eb3-4bcc-ba7d-0c71a5a83895",
   "metadata": {},
   "source": [
    "## Optimizer functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92e8cd7a-9adb-4abd-a60d-010d2ca631a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#If we're not making changes upstream, we can just calculate once\n",
    "#makingChangesUpstreamOfBEGBC20 = True #Moved to top of notebook\n",
    "\n",
    "if not makingChangesUpstreamOfBEGBC20:\n",
    "    setLattice(tao) #Set lattice to current default config\n",
    "    propagateToBEGBC20(centerXYatBEGBC20 = False)\n",
    "    prepareToSimulateFromBEGBC20toEnd()\n",
    "\n",
    "def rampToZero(val, thresh, scale = 1):\n",
    "    return (max(val, thresh) - thresh) / scale\n",
    "\n",
    "def specificOptimizer(\n",
    "    self,\n",
    "    **kwargs\n",
    "):\n",
    "\n",
    "    self.totalNumEvals += 1\n",
    "    self.displayEvals()\n",
    "\n",
    "    savedData = kwargs\n",
    "    \n",
    "    badValue = -1e300  #The value returned for illegal config. Should be colossal. Double limit ~= 1e308\n",
    "    bigCost  = 1e50   #Should be large enough to dominate any \"normal\" return value but be dominated by badValue\n",
    "    \n",
    "    try: #This try block deals with bad configurations. Instead of causing the optimizer to halt we now 'except' a low value\n",
    "        setLattice(tao, **kwargs)\n",
    "\n",
    "    except:\n",
    "        return badValue * 5\n",
    "\n",
    "    if makingChangesUpstreamOfBEGBC20:\n",
    "        try:\n",
    "            propagateToBEGBC20(centerXYatBEGBC20 = False)\n",
    "            prepareToSimulateFromBEGBC20toEnd()\n",
    "        \n",
    "        except:\n",
    "            return badValue * 4\n",
    "\n",
    "    try:\n",
    "        trackBeam(tao)\n",
    "\n",
    "    except:\n",
    "        return badValue * 3\n",
    "\n",
    "    BEGBC20NumLiveParticles = tao.bunch_params(\"BEGBC20\")['n_particle_live']\n",
    "    PENTNumLiveParticles = tao.bunch_params(\"PENT\")['n_particle_live']\n",
    "\n",
    "    if PENTNumLiveParticles < 10:\n",
    "        return badValue * 2 \n",
    "\n",
    "    \n",
    "    # 2024-05-22 NO NO NO! These bunch_params calls are actually returning lattice info because fuck me\n",
    "    #PENTEmitX = tao.bunch_params(\"PENT\")['twiss_norm_emit_x']\n",
    "    #PENTEmitY = tao.bunch_params(\"PENT\")['twiss_norm_emit_y']\n",
    "    #PENTSigmaZ = tao.bunch_params(\"PENT\")['twiss_sigma_z']\n",
    "\n",
    "    # PPENT =  ParticleGroup(data=tao.bunch_data(\"PENT\"))\n",
    "    # PPENT = PPENT[PPENT.status==1]\n",
    "\n",
    "    # PENTEmitX = PPENT[\"norm_emit_x\"]\n",
    "    # PENTEmitY = PPENT[\"norm_emit_y\"]\n",
    "    # PENTSigmaZ = PPENT[\"sigma_t\"]*3e8 #Cannot use std.(\"z\") since Bmad dumps all particles at same z\n",
    "    \n",
    "    try: \n",
    "        P = getBeamAtElement(tao, \"PENT\")\n",
    "        PDrive, PWitness = getDriverAndWitness(P)\n",
    "    \n",
    "\n",
    "        for PActiveStr in [\"PDrive\", \"PWitness\"]:\n",
    "            PActive = locals()[PActiveStr]\n",
    "            for val in [\"mean_x\", \"mean_y\", \"sigma_x\", \"sigma_y\", \"mean_xp\", \"mean_yp\"]:\n",
    "                savedData[f\"{PActiveStr}_{val}\"] = PActive[val]\n",
    "                #print(f\"\"\"{PActiveStr}_{val} = {PActive[val]}\"\"\")\n",
    "\n",
    "            #Note that this is not a standard deviation; also imposes cost for being off zero\n",
    "            savedData[f\"{PActiveStr}_xCost\"] = np.sqrt(np.mean((PActive.x)**2))\n",
    "            savedData[f\"{PActiveStr}_yCost\"] = np.sqrt(np.mean((PActive.y)**2))\n",
    "\n",
    "\n",
    "            #Using the product was making it report flat beams...\n",
    "            #savedData[f\"{PActiveStr}_totalCost\"] = savedData[f\"{PActiveStr}_xCost\"] * savedData[f\"{PActiveStr}_yCost\"]\n",
    "            #Instead, average\n",
    "            savedData[f\"{PActiveStr}_totalCost\"] = 0.5*(savedData[f\"{PActiveStr}_xCost\"] + savedData[f\"{PActiveStr}_yCost\"])\n",
    "\n",
    "            savedData[f\"{PActiveStr}_emitSI90_x\"] = smallestIntervalImpliedEmittance(PActive, plane = \"x\", percentage = 0.90)\n",
    "            savedData[f\"{PActiveStr}_emitSI90_y\"] = smallestIntervalImpliedEmittance(PActive, plane = \"y\", percentage = 0.90)\n",
    "\n",
    "            savedData[f\"{PActiveStr}_zLen\"] = smallestIntervalImpliedSigma(PActive.t * 3e8, percentage=0.9)\n",
    "\n",
    "            savedData[f\"{PActiveStr}_zCentroid\"] = np.median(PActive.t * 3e8)\n",
    "\n",
    "        savedData[\"bunchSpacing\"] = savedData[\"PWitness_zCentroid\"] - savedData[\"PDrive_zCentroid\"]\n",
    "\n",
    "        savedData[\"transverseCentroidOffset\"] = np.sqrt(\n",
    "                (savedData[\"PDrive_mean_x\"] - savedData[\"PWitness_mean_x\"])**2 + \n",
    "                (savedData[\"PDrive_mean_y\"] - savedData[\"PWitness_mean_y\"])**2\n",
    "            )\n",
    "            \n",
    "\n",
    "    except:\n",
    "        return badValue\n",
    "\n",
    "\n",
    "    #Linear cost, weight by bunch\n",
    "    #driveCostWeight = 0.1    \n",
    "    #maximizeMe = 1 / (savedData[\"PWitness_totalCost\"] + driveCostWeight * savedData[\"PDrive_totalCost\"])\n",
    "\n",
    "    #Ramp function cost\n",
    "    #targetBunchSpacing = 100e-6 #Making this a global variable\n",
    "    \n",
    "    tolerableBeamOffset = 5e-6\n",
    "    tolerableAngleOffset = 1e-3\n",
    "    \n",
    "    witnessTransverseSizeCostThreshold = 20e-6\n",
    "    driveTransverseSizeCostThreshold = 20e-6\n",
    "\n",
    "    driveEmittanceThreshold = 50e-6\n",
    "    witnessEmittanceThreshold = 20e-6\n",
    "    \n",
    "    driveLengthCostThreshold =  0\n",
    "    witnessLengthCostThreshold = 0\n",
    "\n",
    "    \n",
    "\n",
    "    # maximizeMe = 1 / (\n",
    "    #     max(witnessCostThreshold, np.sqrt(savedData[\"PWitness_xCost\"])) *  \n",
    "    #     max(witnessCostThreshold, np.sqrt(savedData[\"PWitness_yCost\"]))\n",
    "    #     + driveCostWeight * savedData[\"PDrive_totalCost\"]\n",
    "    # )  \n",
    "\n",
    "\n",
    "    #Using the product was making it prefer flat beams...\n",
    "    # savedData[\"maximizeMe\"] = 1 / (\n",
    "    #     max(witnessTransverseSizeCostThreshold, np.sqrt(savedData[\"PWitness_xCost\"])) +  \n",
    "    #     max(witnessTransverseSizeCostThreshold, np.sqrt(savedData[\"PWitness_yCost\"])) +\n",
    "    #     driveTransverseCostWeight * np.sqrt(savedData[\"PDrive_xCost\"]) +\n",
    "    #     driveTransverseCostWeight * np.sqrt(savedData[\"PDrive_yCost\"]) +\n",
    "    #     max(driverLengthCostThreshold,  savedData[\"PDrive_zLen\"]   ) +\n",
    "    #     max(witnessLengthCostThreshold, savedData[\"PWitness_zLen\"] ) \n",
    "    # )\n",
    "\n",
    "    savedData[\"maximizeMe\"] = 1 / np.mean([\n",
    "        1e6 * rampToZero( abs(savedData[\"bunchSpacing\"] - targetBunchSpacing), 10e-6, scale = 10e-6), \n",
    "        \n",
    "        1e3 * rampToZero(abs(savedData[\"PWitness_mean_x\"]), tolerableBeamOffset, scale = 1e-6),\n",
    "        1e3 * rampToZero(abs(savedData[\"PWitness_mean_y\"]), tolerableBeamOffset, scale = 1e-6),\n",
    "        1e3 * rampToZero(abs(savedData[\"PDrive_mean_x\"]  ), tolerableBeamOffset, scale = 1e-6),\n",
    "        1e3 * rampToZero(abs(savedData[\"PDrive_mean_y\"]  ), tolerableBeamOffset, scale = 1e-6),\n",
    "\n",
    "        1e3 * rampToZero(abs(savedData[\"PWitness_mean_xp\"]), tolerableAngleOffset, scale = 100e-6),\n",
    "        1e3 * rampToZero(abs(savedData[\"PWitness_mean_yp\"]), tolerableAngleOffset, scale = 100e-6),\n",
    "        1e3 * rampToZero(abs(savedData[\"PDrive_mean_xp\"]  ), tolerableAngleOffset, scale = 100e-6),\n",
    "        1e3 * rampToZero(abs(savedData[\"PDrive_mean_yp\"]  ), tolerableAngleOffset, scale = 100e-6),\n",
    "\n",
    "        #optimizerCaresAboutTransverse * 1e3 * rampToZero(savedData[\"transverseCentroidOffset\"], tolerableBeamOffset, scale = 1e-6),\n",
    "  \n",
    "        # rampToZero(savedData[\"PWitness_sigma_x\"], witnessTransverseSizeCostThreshold, scale = 10e-6),  \n",
    "        # rampToZero(savedData[\"PWitness_sigma_y\"], witnessTransverseSizeCostThreshold, scale = 10e-6),\n",
    "        # rampToZero(savedData[\"PDrive_sigma_x\"],   driveTransverseSizeCostThreshold, scale = 10e-6), \n",
    "        # rampToZero(savedData[\"PDrive_sigma_y\"],   driveTransverseSizeCostThreshold, scale = 10e-6),\n",
    "\n",
    "        optimizerCaresAboutTransverse * rampToZero(savedData[\"PDrive_emitSI90_x\"],   driveEmittanceThreshold, scale = 10e-6),\n",
    "        optimizerCaresAboutTransverse * rampToZero(savedData[\"PDrive_emitSI90_y\"],   driveEmittanceThreshold, scale = 10e-6),\n",
    "        optimizerCaresAboutTransverse * rampToZero(savedData[\"PWitness_emitSI90_x\"], witnessEmittanceThreshold, scale = 10e-6),\n",
    "        optimizerCaresAboutTransverse * rampToZero(savedData[\"PWitness_emitSI90_y\"], witnessEmittanceThreshold, scale = 10e-6),\n",
    "        \n",
    "        \n",
    "        rampToZero(savedData[\"PDrive_zLen\"],   driveLengthCostThreshold,   scale = 10e-6),\n",
    "        rampToZero(savedData[\"PWitness_zLen\"], witnessLengthCostThreshold,  scale = 10e-6),\n",
    "\n",
    "        1e-20 #Prevent infinities\n",
    "    ])\n",
    "    \n",
    "    \n",
    "\n",
    "    #Use charge loss to impose cost\n",
    "    worstNumLiveParticles = PENTNumLiveParticles\n",
    "    chargeFractionLiving = worstNumLiveParticles / BEGBC20NumLiveParticles\n",
    "\n",
    "    \n",
    "    if chargeFractionLiving < 0.98:\n",
    "        #If a gradient is desired\n",
    "        #savedData[\"maximizeMe\"] += bigCost * (1-chargeFractionLiving)\n",
    "\n",
    "        #If it's just a threshold\n",
    "        return badValue*0.5\n",
    "  \n",
    "    \n",
    "    #Collect desired data as a pandas Series\n",
    "    tmpData = pd.Series( savedData ) \n",
    "    self.history = pd.concat([self.history, tmpData.to_frame().T])\n",
    "\n",
    "    #Optional: Write to file\n",
    "    self.history.to_json('optimizerHistory.json', orient='records')\n",
    "    \n",
    "    self.updatePlot()\n",
    "\n",
    "\n",
    "    return savedData[\"maximizeMe\"]\n",
    "\n",
    "\n",
    "\n",
    "# def optimizerWrapper( self,\n",
    "#                      #QA10361kG, QA10371kG, QE10425kG, QE10441kG, QE10511kG, QE10525kG,\n",
    "#                      L1PhaseSet, L2PhaseSet, \n",
    "#                      #B1EkG, B2EkG, B3EkG,\n",
    "#                      Q1EkG, Q2EkG, Q3EkG, Q4EkG, Q5EkG, Q6EkG,\n",
    "#                      S1ELkG, S2ELkG, S3ELkG, \n",
    "#                      S3ERkG, S2ERkG, S1ERkG,\n",
    "#                      **kwargs ):\n",
    "#     return specificOptimizer(\n",
    "#         self,\n",
    "#         **{\n",
    "\n",
    "#             # \"QA10361kG\": QA10361kG, \n",
    "#             # \"QA10371kG\": QA10371kG,\n",
    "#             # \"QE10425kG\": QE10425kG,\n",
    "#             # \"QE10441kG\": QE10441kG,\n",
    "#             # \"QE10511kG\": QE10511kG,\n",
    "#             # \"QE10525kG\": QE10525kG,\n",
    "            \n",
    "#             \"L1PhaseSet\": L1PhaseSet, \n",
    "#             \"L2PhaseSet\": L2PhaseSet,\n",
    "            \n",
    "#             #\"B1EkG\": B1EkG,\n",
    "#             #\"B2EkG\": B2EkG,\n",
    "#             #\"B3EkG\": B3EkG,\n",
    "            \n",
    "#             \"Q1EkG\" : Q1EkG,\n",
    "#             \"Q2EkG\" : Q2EkG,\n",
    "#             \"Q3EkG\" : Q3EkG,\n",
    "#             \"Q4EkG\" : Q4EkG,\n",
    "#             \"Q5EkG\" : Q5EkG,\n",
    "#             \"Q6EkG\" : Q6EkG,\n",
    "            \n",
    "#             \"S1ELkG\": S1ELkG,\n",
    "#             \"S2ELkG\": S2ELkG,\n",
    "#             \"S3ELkG\": S3ELkG,\n",
    "#             \"S3ERkG\": S3ERkG,\n",
    "#             \"S2ERkG\": S2ERkG,\n",
    "#             \"S1ERkG\": S1ERkG,\n",
    "#             # \"S3ERkG\": S3ELkG, #Symmetry approx\n",
    "#             # \"S2ERkG\": S2ELkG, #Symmetry approx\n",
    "#             # \"S1ERkG\": S1ELkG, #Symmetry approx\n",
    "            \n",
    "#         }\n",
    "#     )\n",
    "\n",
    "\n",
    "# Function to create optimizerWrapper based on pbounds\n",
    "def create_optimizer_wrapper(pbounds):\n",
    "    param_names = list(pbounds.keys())\n",
    "    \n",
    "    def optimizerWrapper(self, **kwargs):\n",
    "        params = {name: kwargs.get(name, None) for name in param_names}\n",
    "        if None in params.values():\n",
    "            raise ValueError(\"All parameters must be provided\")\n",
    "        return specificOptimizer(self, **params)\n",
    "    \n",
    "    return optimizerWrapper\n",
    "\n",
    "# Create the optimizerWrapper function\n",
    "optimizerWrapper = create_optimizer_wrapper(pbounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "135416a5-3997-4904-babd-8a91fe22499d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0moptimizerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m      /var/folders/3j/4b_6gm4j44z6mpdlh3f3ggjc0000gn/T/ipykernel_42195/546556832.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?optimizerWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ac59a2-b323-4acb-ac99-b9b65c6573d2",
   "metadata": {},
   "source": [
    "## Do optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125b726c-ad45-4c40-870a-5d34b3d0d194",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### General optimizer setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7955b78-5c54-4205-80b8-cf73062fa36b",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OptimizationProblem:\n",
    "    def __init__(self):\n",
    "        self.history = pd.DataFrame()\n",
    "        self.totalNumEvals = 0\n",
    "        self.plot_display_handle = None\n",
    "        self.evals_display_handle = None\n",
    "\n",
    "\n",
    "    def updatePlot(self):\n",
    "        plt.figure()\n",
    "        plotKey = \"maximizeMe\"\n",
    "        plt.plot(np.arange(len(self.history[plotKey])), self.history[plotKey], '-')\n",
    "        \n",
    "        plt.title('Optimization History')\n",
    "        plt.xlabel('Evaluation #')\n",
    "        plt.ylabel(plotKey)\n",
    "        plt.yscale('log')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        \n",
    "        if self.plot_display_handle is None:\n",
    "            self.plot_display_handle = display(plt.gcf(), display_id=True)\n",
    "        else:\n",
    "            update_display(plt.gcf(), display_id=self.plot_display_handle.display_id)\n",
    "        plt.close()\n",
    "\n",
    "    def displayEvals(self):\n",
    "        if self.evals_display_handle is None:\n",
    "            self.evals_display_handle = display(f\"Total Num Evals: {self.totalNumEvals}\", display_id=True)\n",
    "        else:\n",
    "            update_display(f\"Total Num Evals: {self.totalNumEvals}\", display_id=self.evals_display_handle.display_id)\n",
    "\n",
    "# Attach the function to the class as a method\n",
    "OptimizationProblem.optimizerWrapper = optimizerWrapper\n",
    "\n",
    "# Instantiate the optimization problem\n",
    "problem = OptimizationProblem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9a9ca6-197b-4dfa-b2a1-7cdf1fa64324",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe991c2b-8df7-4794-b28e-8b496bc718dd",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bounded region of parameter space\n",
    "#2024-05-15: Out of abundance of caution, always comment out unused vars, even if using **kwargs stops errors from being thrown\n",
    "# pbounds = {\n",
    "#     #'L1PhaseSet': (-40, -20),\n",
    "#     #'L2PhaseSet': (-50, -30),\n",
    "    \n",
    "#     #\"B1EkG\": makeBoundsTuple(boundsRange, 7.533),\n",
    "#     #\"B2EkG\": makeBoundsTuple(boundsRange, -10.942),\n",
    "#     #\"B3EkG\": makeBoundsTuple(boundsRange, 3.409),\n",
    "\n",
    "#     \"Q1EkG\": makeBoundsTuple(quadBoundsRange, 161.311),\n",
    "#     \"Q2EkG\": makeBoundsTuple(quadBoundsRange, -154.229),\n",
    "#     \"Q3EkG\": makeBoundsTuple(quadBoundsRange, 110.217),\n",
    "#     \"Q4EkG\": makeBoundsTuple(quadBoundsRange, 132.268),\n",
    "#     \"Q5EkG\": makeBoundsTuple(quadBoundsRange, -23.373),\n",
    "#     \"Q6EkG\": makeBoundsTuple(quadBoundsRange, -142.271),\n",
    "\n",
    "#      \"S1ELkG\": makeBoundsTuple(sextBoundsRange, 804.871),\n",
    "#      \"S2ELkG\": makeBoundsTuple(sextBoundsRange, -2049.489),\n",
    "#      \"S3ELkG\": makeBoundsTuple(sextBoundsRange, -1019.3230),\n",
    "#      \"S3ERkG\": makeBoundsTuple(sextBoundsRange, -1019.3230),\n",
    "#      \"S2ERkG\": makeBoundsTuple(sextBoundsRange, -2049.489),\n",
    "#      \"S1ERkG\": makeBoundsTuple(sextBoundsRange, 804.871),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bca3847-49ed-45c5-8550-d21604466ecb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8511082-bb92-4f87-841f-34f29a290f48",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "534b895c-211e-40c2-aa63-eaf6fca2e347",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# optimizer = bayes_opt.BayesianOptimization(\n",
    "#     f=problem.optimizerWrapper,\n",
    "#     pbounds=pbounds,\n",
    "#     random_state=7,\n",
    "#     allow_duplicate_points=True, #2024-04-26 it was whining about this,\n",
    "#     verbose = 0 #2024-05-22: Make it quiet\n",
    "# )\n",
    "\n",
    "# #Initial point(s) to check\n",
    "# optimizer.probe(\n",
    "#     params={\n",
    "# 'Q1EkG': 117.05888832887702,\n",
    "#  'Q2EkG': -161.08070347179788,\n",
    "#  'Q3EkG': 123.62696608961151,\n",
    "#  'Q4EkG': 99.94203817364581,\n",
    "#  'Q5EkG': -31.456534919110677,\n",
    "#  'Q6EkG': -105.01493924928589,\n",
    "#  'S1ELkG': 453.142910378237,\n",
    "#  'S2ELkG': -1988.4701652598128,\n",
    "#  'S3ELkG': -985.7586439934659,\n",
    "#  'S3ERkG': -564.5394965036853,\n",
    "#  'S2ERkG': -1592.1135118613981,\n",
    "#  'S1ERkG': 869.2610562040793\n",
    "# },\n",
    "#     lazy=True,\n",
    "# )\n",
    "\n",
    "# #Refer to https://bayesian-optimization.github.io/BayesianOptimization/exploitation_vs_exploration.html\n",
    "# #and https://github.com/bayesian-optimization/BayesianOptimization/blob/master/bayes_opt/bayesian_optimization.py\n",
    "# boInitialKappa = 10 + 0*10.\n",
    "# boFinalKappa = 1e-3 + 0*0.1\n",
    "# boNumIter = 1000\n",
    "# boKappaDecay = (boFinalKappa / boInitialKappa)**(1/boNumIter)\n",
    "\n",
    "# acquisition_function = bayes_opt.util.UtilityFunction(kind='ucb',\n",
    "#                                    kappa=boInitialKappa,         #Default 2.576\n",
    "#                                    xi=0.0,              #Default 0\n",
    "#                                    kappa_decay=boKappaDecay,       #Default 0\n",
    "#                                    kappa_decay_delay=0  #Default 0                     \n",
    "#                                           )\n",
    "\n",
    "\n",
    "# optimizer.maximize(\n",
    "#     init_points=0, #Initial, random points\n",
    "#     n_iter=boNumIter,\n",
    "#     acquisition_function=acquisition_function\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18466126-c458-42c7-808e-b9a2ad6699c3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Differential evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "636c9a69-ac6f-406c-b7c7-1a0801da07bc",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "# Convert pbounds to the format required by differential_evolution\n",
    "bounds = [(low, high) for (low, high) in pbounds.values()]\n",
    "param_names = list(pbounds.keys())\n",
    "\n",
    "#scipy.optimize wants to optimize a function which is passed a vector of all the parameters\n",
    "#This programmatically wraps the existing wrapper (ugh...) to handle this format\n",
    "def create_DE_wrapper(obj, param_names):\n",
    "    def wrapperDE(params):\n",
    "        param_dict = dict(zip(param_names, params))\n",
    "\n",
    "        #bayes_opt is a maximizer but differential_evolution is a minimizer... hence the inversion\n",
    "        return -1*obj.optimizerWrapper(**param_dict)\n",
    "    \n",
    "    return wrapperDE\n",
    "\n",
    "wrapperDE = create_DE_wrapper(problem, param_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7f31e31-5341-450a-bfac-326099414b30",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "defaultSettingsVector = [importedDefaultSettings[key] for key in list(pbounds.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7ebd49-0d7c-409d-9d2d-07bd56ea625e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total Num Evals: 1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Optional: Define list of starting points\n",
    "totalPopSize = 50  # Total population size\n",
    "numDimensions = len(bounds)  # Number of parameters\n",
    "\n",
    "#Uniformly distributed\n",
    "populationDE = np.random.rand(totalPopSize, numDimensions)\n",
    "for i in range(numDimensions):\n",
    "    low, high = bounds[i]\n",
    "    populationDE[:, i] = low + populationDE[:, i] * (high - low)\n",
    "\n",
    "#Normally distributed\n",
    "# populationDE = np.zeros((totalPopSize, numDimensions))\n",
    "# for i in range(numDimensions):\n",
    "#     low, high = bounds[i]\n",
    "\n",
    "#     #Define mean based on bounds\n",
    "#     #mean = (high + low) / 2\n",
    "\n",
    "#     #Optional: Define mean based on defaultSettingsVector\n",
    "#     mean = defaultSettingsVector[i]\n",
    "    \n",
    "#     std_dev = (high - low) / 5\n",
    "#     populationDE[:, i] = np.random.normal(mean, std_dev, totalPopSize)\n",
    "\n",
    "#Optional: Add specific points to initial evaluation list\n",
    "populationDE = np.vstack([[ defaultSettingsVector ], populationDE])\n",
    "\n",
    "# result = differential_evolution(\n",
    "#     wrapperDE, \n",
    "#     bounds,\n",
    "#     maxiter=100, \n",
    "#     disp=True,\n",
    "#     polish = False, \n",
    "#     init = populationDE\n",
    "# )\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "#Optional: Manually define starting simplex\n",
    "# initial_simplex = np.tile(defaultSettingsVector, (numDimensions + 1, 1))\n",
    "# for i in range(1, numDimensions + 1):\n",
    "#     initial_simplex[i][i - 1] *= 1.1\n",
    "\n",
    "result = minimize(\n",
    "    wrapperDE, \n",
    "    defaultSettingsVector,\n",
    "    method = \"Nelder-Mead\",\n",
    "    bounds = bounds,\n",
    "    #options={'initial_simplex': initial_simplex}\n",
    ")\n",
    "\n",
    "# result = minimize(\n",
    "#     wrapperDE, \n",
    "#     defaultSettingsVector,\n",
    "#     method = \"L-BFGS-B\",\n",
    "#     bounds = bounds,\n",
    "#     options = {\"eps\": [0.001*x for x in defaultSettingsVector]}\n",
    "# )\n",
    "\n",
    "print(problem.history) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537d5d94-ee16-4a6d-af06-53139a015f2b",
   "metadata": {},
   "source": [
    "## Check out results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50f42b1-5f6b-4a17-99ac-3902f40189bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem.history.to_csv('output_data.csv', index=False)\n",
    "\n",
    "problem.history = problem.history.sort_values(by='maximizeMe', ascending=False)\n",
    "\n",
    "\n",
    "bestConfigData = problem.history.iloc[0]\n",
    "bestConfigDict = bestConfigData.to_dict()\n",
    "\n",
    "print( bestConfigData ) \n",
    "\n",
    "\n",
    "\n",
    "setLattice(tao, **bestConfigDict)\n",
    "\n",
    "\n",
    "trackBeam(tao)\n",
    "\n",
    "P = getBeamAtElement(tao, \"PENT\")\n",
    "PDrive, PWitness = getDriverAndWitness(P)\n",
    "\n",
    "print(f\"\"\"P, sigma x: {P[\"sigma_x\"]}\"\"\")\n",
    "print(f\"\"\"PDrive, sigma x: {PDrive[\"sigma_x\"]}\"\"\")\n",
    "print(f\"\"\"PWitness, sigma x: {PWitness[\"sigma_x\"]}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dec3b8-84cd-4210-955d-3ff84b7e60b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestConfigDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041feb20-cbd4-4875-a53a-27e1673b6381",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(plotMod(P, 'x', 'y',  bins=300))\n",
    "display(plotMod(P, 'x', 'pz', bins=300))\n",
    "display(plotMod(P, 'x', 'xp', bins=300))\n",
    "display(plotMod(P, 'y', 'yp', bins=300))\n",
    "display(plotMod(P, 'delta_t', 'pz', bins=300))\n",
    "display(slicePlotMod(P, 'norm_emit_x',n_slice=100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e145e5-5de1-4039-8a0e-7615383bd0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(plotMod(PWitness, 'x', 'y',  bins=300))\n",
    "display(plotMod(PWitness, 'x', 'pz', bins=300))\n",
    "display(plotMod(PWitness, 'x', 'xp', bins=300))\n",
    "display(plotMod(PWitness, 'y', 'yp', bins=300))\n",
    "display(plotMod(PWitness, 'delta_t', 'pz', bins=300))\n",
    "display(slicePlotMod(PWitness, 'norm_emit_x',n_slice=100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e873d9e9-c62f-40e3-859e-798648f88cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"P, sigma x: {P[\"sigma_x\"]}\"\"\")\n",
    "print(f\"\"\"PDrive, sigma x: {PDrive[\"sigma_x\"]}\"\"\")\n",
    "print(f\"\"\"PWitness, sigma x: {PWitness[\"sigma_x\"]}\"\"\")\n",
    "\n",
    "display(plotMod(P, 'x', 'y',  bins=300))\n",
    "display(plotMod(PDrive, 'x', 'y',  bins=300))\n",
    "display(plotMod(PWitness, 'x', 'y',  bins=300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9d5824-6cf6-4e11-8aae-00d366d69c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = getBeamAtElement(tao, \"MFFF\")\n",
    "\n",
    "display(plotMod(P, 'x', 'xp', bins=300))\n",
    "display(slicePlotMod(P, 'norm_emit_x',n_slice=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7c2188-44ab-4d6b-8d52-bbb3c47f758d",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
